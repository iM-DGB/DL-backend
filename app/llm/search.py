import os
import numpy as np
import psycopg2
from psycopg2.extras import RealDictCursor
from app.utils.logger import logger
from app.llm.embedding import embed_query_locally

def get_pg_connection():
    return psycopg2.connect(
        dbname=os.getenv("PG_DB"),
        user=os.getenv("PG_USER"),
        password=os.getenv("PG_PASSWORD"),
        host=os.getenv("PG_HOST"),
        port=os.getenv("PG_PORT"),
        sslmode="require"
    )

def get_relevant_chunks_pgvector(query: str, category: str, top_k=5):
    logger.info("ğŸ§  ë¡œì»¬ ì„ë² ë”© ìƒì„± ì¤‘...")
    query_vector = embed_query_locally(query)

    logger.info("ğŸ“¡ PostgreSQL ë‚´ ìœ ì‚¬ë„ ì •ë ¬ ìˆ˜í–‰ ì¤‘...")
    conn = get_pg_connection()
    cur = conn.cursor(cursor_factory=RealDictCursor)

    cur.execute("""
        SELECT document, cmetadata->>'product_name' AS product_name,
               1 - (embedding <=> %s::vector) AS score
        FROM langchain_pg_embedding
        WHERE collection_id = (
            SELECT uuid FROM langchain_pg_collection WHERE name = 'insurance_docs'
        )
        AND cmetadata->>'category' = %s
        ORDER BY embedding <=> %s::vector
        LIMIT %s
    """, (query_vector.tolist(), category, query_vector.tolist(), top_k))

    rows = cur.fetchall()
    cur.close()
    conn.close()

    if not rows:
        logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ.")
        return {
            "recommended_product": None,
            "top_chunks": [],
            "related_products": []
        }

    seen_chunks = set()
    top_chunks, top_names = [], []

    for row in rows:
        content = row["document"].strip()
        if content not in seen_chunks:
            seen_chunks.add(content)
            top_chunks.append(content)
            top_names.append(row["product_name"])
            logger.info(f"ğŸ”¹ ì¶”ì²œ: {row['product_name']} | ìœ ì‚¬ë„: {row['score']:.4f}")

    recommended_product = max(set(top_names), key=top_names.count)
    related_products = list(dict.fromkeys(top_names))

    logger.info(f"ğŸ† ìµœì¢… ì¶”ì²œ ìƒí’ˆ: {recommended_product}")
    return {
        "recommended_product": recommended_product,
        "top_chunks": top_chunks,
        "related_products": related_products
    }

def get_relevant_chunks_fast(query: str, category: str, top_k=5):
    logger.info("ğŸ§  ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì¤‘...")
    embedder = UpstageEmbeddings(
        model="solar-embedding-1-large",
        api_key=os.getenv("SOLAR_API_KEY")
    )
    query_vector = embedder.embed_query(query)

    logger.info("ğŸ“¡ PostgreSQLì—ì„œ ë²¡í„° ê²€ìƒ‰ ì¤‘...")
    conn = get_pg_connection()
    cur = conn.cursor(cursor_factory=RealDictCursor)

    # ğŸ” í•„í„°ë§ ì¡°ê±´ ì¶”ê°€ (ì¹´í…Œê³ ë¦¬ í•„í„°)
    cur.execute("""
        SELECT page_content, product_name, embedding
        FROM langchain_pg_embedding
        WHERE collection_id = (
            SELECT uuid FROM langchain_pg_collection WHERE name = 'insurance_docs'
        )
        AND metadata ->> 'category' = %s
    """, (category,))
    
    rows = cur.fetchall()
    cur.close()
    conn.close()

    if not rows:
        logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {
            "recommended_product": None,
            "top_chunks": [],
            "related_products": []
        }

    logger.info(f"ğŸ“„ ì´ í›„ë³´ ì²­í¬ ìˆ˜: {len(rows)}")

    # ğŸ”¢ ìœ ì‚¬ë„ ê³„ì‚°
    contents, vectors, names = [], [], []
    for row in rows:
        embedding_str = row['embedding']
        vector = np.array(embedding_str[1:-1].split(','), dtype=np.float32)
        vectors.append(vector)
        contents.append(row['page_content'])
        names.append(row['product_name'])

    similarities = cosine_similarity([query_vector], vectors)[0]
    ranked = sorted(zip(contents, names, similarities), key=lambda x: x[2], reverse=True)
    top_docs = ranked[:top_k]

    seen_chunks = set()
    top_chunks, top_names = [], []

    for text, pname, score in top_docs:
        if text not in seen_chunks:
            seen_chunks.add(text)
            top_chunks.append(text)
            top_names.append(pname)
            logger.info(f"ğŸ”¹ ì¶”ì²œ: {pname} | ìœ ì‚¬ë„: {score:.4f}")

    recommended_product = max(set(top_names), key=top_names.count)
    related_products = list(dict.fromkeys(top_names))

    logger.info(f"ğŸ† ìµœì¢… ì¶”ì²œ ìƒí’ˆ: {recommended_product}")
    return {
        "recommended_product": recommended_product,
        "top_chunks": top_chunks,
        "related_products": related_products
    }

# def get_vector_db():
#     embedder = UpstageEmbeddings(
#         model="solar-embedding-1-large",
#         api_key=os.getenv("SOLAR_API_KEY")
#     )
#     connection_string = (
#         f"postgresql+psycopg://{os.getenv('PG_USER')}:{os.getenv('PG_PASSWORD')}"
#         f"@{os.getenv('PG_HOST')}:{os.getenv('PG_PORT')}/{os.getenv('PG_DB')}?sslmode=require"
#     )
#     db = PGVector(
#         collection_name="insurance_docs",
#         connection_string=connection_string,
#         embedding_function=embedder,
#     )
#     return db, embedder



# def search_exact_product(category: str, product_name: str):
#     db, _ = get_vector_db()
#     filter = {"category": category, "product_name": product_name}
#     docs = db.similarity_search(query="í•´ë‹¹ ìƒí’ˆ ì„¤ëª…", k=1, filter=filter)
#     return [doc.page_content for doc in docs]


# def search_similar_product(query: str, category: str, top_k=5, fetch_k=30):
#     db, _ = get_vector_db()
#     filter = {"category": category}
#     docs = db.similarity_search(query, k=fetch_k, filter=filter)

#     seen = set()
#     product_names = []
#     for doc in docs:
#         pname = doc.metadata.get("product_name")
#         if pname and pname not in seen:
#             seen.add(pname)
#             product_names.append(pname)
#         if len(product_names) >= top_k:
#             break

#     logger.info(f"ğŸ¯ ìœ ì‚¬ ìƒí’ˆ í›„ë³´: {product_names}")
#     return product_names



# def get_relevant_chunks(query: str, category: str, top_k=5, product_top_k=10):
#     db, embedder = get_vector_db()

#     product_names = search_similar_product(query, category, top_k=product_top_k)
#     if not product_names:
#         return {
#             "recommended_product": None,
#             "top_chunks": [],
#             "related_products": [],
#             "similarity_avg": 0.0
#         }

#     all_docs = []
#     seen_chunks = set()

#     for pname in product_names:
#         docs = db.similarity_search(query, k=10, filter={"category": category, "product_name": pname})
#         for doc in docs:
#             chunk = doc.page_content.strip()
#             if chunk not in seen_chunks:
#                 seen_chunks.add(chunk)
#                 all_docs.append(doc)

#     if not all_docs:
#         return {
#             "recommended_product": None,
#             "top_chunks": [],
#             "related_products": [],
#             "similarity_avg": 0.0
#         }

#     query_vector = embedder.embed_query(query)
#     doc_texts = [doc.page_content for doc in all_docs]
#     doc_vectors = embedder.embed_documents(doc_texts)
#     similarities = cosine_similarity([query_vector], doc_vectors)[0]

#     ranked = sorted(zip(all_docs, similarities), key=lambda x: x[1], reverse=True)
#     top_docs = ranked[:top_k]

#     top_chunks = []
#     top_product_names = []
#     top_similarities = []
#     chunk_seen = set()

#     for i, (doc, score) in enumerate(top_docs):
#         pname = doc.metadata.get("product_name", "ì•Œ ìˆ˜ ì—†ìŒ")
#         logger.info(f"ğŸ”¹ Top{i+1} | ìƒí’ˆëª…: {pname}, ìœ ì‚¬ë„: {score:.4f}")

#         content = doc.page_content.strip()
#         if content not in chunk_seen:
#             chunk_seen.add(content)
#             top_chunks.append(content)
#             top_product_names.append(pname)
#             top_similarities.append(score)

#     recommended_product = max(set(top_product_names), key=top_product_names.count)
#     related_products = list(dict.fromkeys(top_product_names))
#     similarity_avg = sum(top_similarities) / len(top_similarities) if top_similarities else 0.0

#     logger.info(f"ğŸ† ìµœì¢… ì¶”ì²œ ìƒí’ˆ: {recommended_product}")
#     logger.info(f"ğŸ“¦ ê´€ë ¨ ìƒí’ˆ í›„ë³´: {related_products}")
#     logger.info(f"ğŸ“ˆ í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜: {similarity_avg:.4f}")

#     return {
#         "recommended_product": recommended_product,
#         "top_chunks": top_chunks,
#         "related_products": related_products,
#         "similarity_avg": round(similarity_avg, 4)
#     }
